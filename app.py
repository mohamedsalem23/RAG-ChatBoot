from dotenv import load_dotenv

import streamlit as st
from utils import parse_markdown_table_to_df
from rag_chain import build_rag_chain
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()



# Page title
st.set_page_config(
    page_title="Ø´Ø§Øª Ø¨ÙˆØª ÙƒÙ„ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - Ø¬Ø§Ù…Ø¹Ø© ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®",
    page_icon="ğŸ¤–",
    layout="wide"
)

# CSS to support Arabic (RTL) and improve UI
st.markdown("""
    <style>
    .main {
        direction: rtl;
        text-align: right;
    }
    .stChatMessage {
        direction: rtl;
    }
    .chat-container {
        max-width: 800px;
        margin: 0 auto;
    }
    </style>
""", unsafe_allow_html=True)

# Main interface
st.title("ğŸ¤– Ø´Ø§Øª Ø¨ÙˆØª ÙƒÙ„ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - Ø¬Ø§Ù…Ø¹Ø© ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®")
st.markdown("---")

# Build the Chain
rag_chain = build_rag_chain()

if rag_chain is None:
    st.stop()

# Chat session (session state)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "assistant" and "table" in message.get("type", ""):
            # If the reply contains a table, display it as a DataFrame
            df = parse_markdown_table_to_df(message["content"])
            if df is not None:
                st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                st.markdown(message["content"])
        else:
            st.markdown(message["content"])

# User input
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... (Ù…Ø«Ù„: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© 1 ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯ØŸ)"):
    # Add the question
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # The reply
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø¯..."):
            response = rag_chain.invoke(prompt)
        
        # Parse the response: if there's a Markdown table, convert it to a DataFrame
        df = parse_markdown_table_to_df(response)
        if df is not None:
            st.dataframe(df, use_container_width=True, hide_index=True)
            # Add the reply with type "table" for storage
            st.session_state.messages.append({"role": "assistant", "content": response, "type": "table"})
        else:
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
with st.sidebar:
   
    st.markdown("---")
    st.info("Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ù‡ ØªÙ…Ø§Ù…Ø§ ÙˆÙ„Ø§ ÙŠØ¹ØªØ¯ Ø¹Ù„ÙŠÙ‡Ø§ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙŠØ±Ø¬ÙŠ Ø§Ù„Ø±Ø¬ÙˆØ¹ Ù„Ù„ÙƒÙ„ÙŠØ©")